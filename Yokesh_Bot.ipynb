{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8m8BNl8BUNf",
        "outputId": "1ef16cd5-6b0b-4862-da71-38c99860c265"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.12.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.14.1)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.97.1\n",
            "    Uninstalling openai-1.97.1:\n",
            "      Successfully uninstalled openai-1.97.1\n",
            "Successfully installed openai-0.28.0 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBXgXjgA3iKe",
        "outputId": "7ebfb0a4-870c-43ce-a123-f75cc6b63ccb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/chatbot_yokesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwJ4mDja4vdX",
        "outputId": "1854670b-24e7-418f-88de-c8e7c3da2df2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa2NLoIQ5HPm",
        "outputId": "4eab40ec-0bc1-4ee5-d570-d0cb619cf65b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/content/drive/MyDrive/chatbot_yokesh/.env\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blb2cU_w46BG",
        "outputId": "3c078e75-6a71-4abe-8b39-da094dba5d4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR8aFPMW57SG",
        "outputId": "f26b4b4d-956b-422b-8dd5-eb3cdf493556"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def chatbot():\n",
        "  # Create a list to store all the messages for context\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "  ]\n",
        "\n",
        "  # Keep repeating the following\n",
        "  while True:\n",
        "    # Prompt user for input\n",
        "    message = input(\"User: \")\n",
        "\n",
        "    # Exit program if user inputs \"quit\"\n",
        "    if message.lower() == \"quit\":\n",
        "      break\n",
        "\n",
        "    # Add each new message to the list\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Request gpt-3.5-turbo for chat completion\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=messages\n",
        "    )\n",
        "\n",
        "    # Print the response and add it to the messages list\n",
        "    chat_message = response['choices'][0]['message']['content']\n",
        "    print(f\"Bot: {chat_message}\")\n",
        "    messages.append({\"role\": \"assistant\", \"content\": chat_message})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
        "  chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MxTvM1R6Cn2",
        "outputId": "b6b8a963-581c-428f-a4a5-c488994895b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot (type 'quit' to stop)!\n",
            "User: who is indira gandhi?\n",
            "Bot: Indira Gandhi was an Indian politician who served as the Prime Minister of India for three consecutive terms from 1966 to 1977 and then again from 1980 until her assassination in 1984. She was the first and, to date, the only female Prime Minister of India. Gandhi was known for her strong leadership and controversial decisions during her tenure.\n",
            "User: who is his son?\n",
            "Bot: Indira Gandhi's son was Rajiv Gandhi. He also served as the Prime Minister of India, following the assassination of his mother in 1984. Rajiv Gandhi served as Prime Minister from 1984 to 1989. He was known for his efforts to modernize India and promote technology and telecommunications.\n",
            "User: family tree \n",
            "Bot: Sure, here is a simplified family tree of the Gandhi family:\n",
            "\n",
            "- Motilal Nehru and Swarup Rani Nehru\n",
            "  - Jawaharlal Nehru and Kamala Nehru\n",
            "    - Indira Gandhi (married Feroze Gandhi)\n",
            "      - Rajiv Gandhi (married Sonia Gandhi)\n",
            "        - Rahul Gandhi\n",
            "        - Priyanka Gandhi-Vadra\n",
            "\n",
            "Please note that this family tree is a simplified version and does not include all members of the extended Gandhi family.\n",
            "User: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrOZiPKi-eOp",
        "outputId": "d6dae137-53ac-4410-d6d7-79dfccba5e35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m786.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.12 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "\n",
        "# ‚úÖ Load API key from your .env file\n",
        "load_dotenv(\"/content/drive/MyDrive/chatbot_yokesh/.env\")\n",
        "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# ‚úÖ Token pricing\n",
        "TOKEN_PRICES = {\n",
        "    \"gpt-4\": {\"input\": 0.03 / 1000, \"output\": 0.06 / 1000},\n",
        "    \"gpt-3.5-turbo\": {\"input\": 0.0015 / 1000, \"output\": 0.002 / 1000}\n",
        "}\n",
        "\n",
        "# ‚úÖ Streamlit setup\n",
        "st.set_page_config(page_title=\"Supply Chain Chatbot\", layout=\"centered\")\n",
        "st.title(\"ü§ñ Supply Chain & Warehouse Automation Chatbot\")\n",
        "\n",
        "# ‚úÖ Model selector\n",
        "model_choice = st.sidebar.selectbox(\"Select Model\", [\"gpt-4\", \"gpt-3.5-turbo\"])\n",
        "\n",
        "# ‚úÖ Session state\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that ONLY answers questions about Supply Chain, Warehouse Automation, and AutoStore systems. If the user asks anything outside this domain, politely refuse.\"}\n",
        "    ]\n",
        "if \"total_cost\" not in st.session_state:\n",
        "    st.session_state.total_cost = 0.0\n",
        "if \"last_user_input\" not in st.session_state:\n",
        "    st.session_state.last_user_input = None\n",
        "\n",
        "# ‚úÖ Show chat history\n",
        "for msg in st.session_state.messages[1:]:\n",
        "    if msg[\"role\"] == \"user\":\n",
        "        st.markdown(f\"üßë‚Äçüíº **You:** {msg['content']}\")\n",
        "    else:\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{msg['content']}\")\n",
        "\n",
        "# ‚úÖ Domain check with context awareness\n",
        "def is_domain_question(user_input, messages):\n",
        "    domain_keywords = [\"warehouse\", \"autostore\", \"inventory\", \"automation\", \"supply chain\", \"fulfillment\", \"logistics\"]\n",
        "    if any(word in user_input.lower() for word in domain_keywords):\n",
        "        return True\n",
        "    # allow follow-up if last user question was in domain\n",
        "    for msg in reversed(messages):\n",
        "        if msg[\"role\"] == \"user\":\n",
        "            if any(word in msg[\"content\"].lower() for word in domain_keywords):\n",
        "                return True\n",
        "            break\n",
        "    return False\n",
        "\n",
        "# ‚úÖ Chat input\n",
        "user_input = st.chat_input(\"Type your question:\")\n",
        "\n",
        "if user_input and user_input != st.session_state.last_user_input:\n",
        "    st.session_state.last_user_input = user_input\n",
        "\n",
        "    # ‚úÖ Display question immediately\n",
        "    st.markdown(f\"üßë‚Äçüíº **You:** {user_input}\")\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    if not is_domain_question(user_input, st.session_state.messages):\n",
        "        bot_reply = \"‚ö†Ô∏è This chatbot only answers questions related to Supply Chain, Warehouse Automation, and AutoStore systems.\"\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{bot_reply}\")\n",
        "    else:\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_choice,\n",
        "                messages=st.session_state.messages,\n",
        "                max_tokens=300,\n",
        "                temperature=0.5\n",
        "            )\n",
        "        bot_reply = response.choices[0].message.content.strip()\n",
        "        bot_reply = bot_reply.replace(\"\\n\\n\", \"\\n\")  # ‚úÖ Clean formatting\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{bot_reply}\")\n",
        "\n",
        "        # ‚úÖ Calculate cost\n",
        "        prompt_tokens = response.usage.prompt_tokens\n",
        "        completion_tokens = response.usage.completion_tokens\n",
        "        cost = (\n",
        "            prompt_tokens * TOKEN_PRICES[model_choice][\"input\"] +\n",
        "            completion_tokens * TOKEN_PRICES[model_choice][\"output\"]\n",
        "        )\n",
        "        st.session_state.total_cost += cost\n",
        "\n",
        "# ‚úÖ Reset button\n",
        "if st.sidebar.button(\"üîÑ Reset Conversation\"):\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that ONLY answers questions about Supply Chain, Warehouse Automation, and AutoStore systems.\"}\n",
        "    ]\n",
        "    st.session_state.total_cost = 0.0\n",
        "    st.session_state.last_user_input = None\n",
        "    st.rerun()\n",
        "\n",
        "# ‚úÖ Sidebar cost display\n",
        "st.sidebar.markdown(\"### üí∞ Session Cost\")\n",
        "st.sidebar.write(f\"Estimated Cost: **${st.session_state.total_cost:.4f}**\")\n",
        "\n",
        "# ‚úÖ Debug conversation\n",
        "with st.sidebar.expander(\"üîç Debug - Conversation Log\"):\n",
        "    st.text_area(\"Model Input\", value=json.dumps(st.session_state.messages, indent=2), height=300)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AivwFbNTG7I",
        "outputId": "2cd494db-cca8-42b0-a9a4-9bedecc61c30"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "\n",
        "# ‚úÖ Load API key from local .env if available\n",
        "load_dotenv(\"/content/drive/MyDrive/chatbot_yokesh/.env\")\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# ‚úÖ If running on Streamlit Cloud, fallback to st.secrets\n",
        "if not api_key and \"OPENAI_API_KEY\" in st.secrets:\n",
        "    api_key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# ‚úÖ Safety check\n",
        "if not api_key:\n",
        "    st.error(\"‚ùå OPENAI_API_KEY not found! Set it in `.env` (local) or Streamlit Secrets (cloud).\")\n",
        "    st.stop()\n",
        "\n",
        "# ‚úÖ Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# ‚úÖ Token pricing\n",
        "TOKEN_PRICES = {\n",
        "    \"gpt-4\": {\"input\": 0.03 / 1000, \"output\": 0.06 / 1000},\n",
        "    \"gpt-3.5-turbo\": {\"input\": 0.0015 / 1000, \"output\": 0.002 / 1000}\n",
        "}\n",
        "\n",
        "# ‚úÖ Streamlit setup\n",
        "st.set_page_config(page_title=\"Supply Chain Chatbot\", layout=\"centered\")\n",
        "st.title(\"ü§ñ Supply Chain & Warehouse Automation Chatbot\")\n",
        "\n",
        "# ‚úÖ Model selector\n",
        "model_choice = st.sidebar.selectbox(\"Select Model\", [\"gpt-4\", \"gpt-3.5-turbo\"])\n",
        "\n",
        "# ‚úÖ Session state\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that ONLY answers questions about Supply Chain, Warehouse Automation, and AutoStore systems. If the user asks anything outside this domain, politely refuse.\"}\n",
        "    ]\n",
        "if \"total_cost\" not in st.session_state:\n",
        "    st.session_state.total_cost = 0.0\n",
        "if \"last_user_input\" not in st.session_state:\n",
        "    st.session_state.last_user_input = None\n",
        "\n",
        "# ‚úÖ Display history\n",
        "for msg in st.session_state.messages[1:]:\n",
        "    if msg[\"role\"] == \"user\":\n",
        "        st.markdown(f\"üßë‚Äçüíº **You:** {msg['content']}\")\n",
        "    else:\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{msg['content']}\")\n",
        "\n",
        "# ‚úÖ Domain check with context awareness\n",
        "def is_domain_question(user_input, messages):\n",
        "    domain_keywords = [\"warehouse\", \"autostore\", \"inventory\", \"automation\", \"supply chain\", \"fulfillment\", \"logistics\"]\n",
        "    if any(word in user_input.lower() for word in domain_keywords):\n",
        "        return True\n",
        "    for msg in reversed(messages):\n",
        "        if msg[\"role\"] == \"user\":\n",
        "            if any(word in msg[\"content\"].lower() for word in domain_keywords):\n",
        "                return True\n",
        "            break\n",
        "    return False\n",
        "\n",
        "# ‚úÖ Chat input\n",
        "user_input = st.chat_input(\"Type your question:\")\n",
        "\n",
        "if user_input and user_input != st.session_state.last_user_input:\n",
        "    st.session_state.last_user_input = user_input\n",
        "\n",
        "    # ‚úÖ Show user question immediately\n",
        "    st.markdown(f\"üßë‚Äçüíº **You:** {user_input}\")\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    if not is_domain_question(user_input, st.session_state.messages):\n",
        "        bot_reply = \"‚ö†Ô∏è This chatbot only answers questions related to Supply Chain, Warehouse Automation, and AutoStore systems.\"\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{bot_reply}\")\n",
        "    else:\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_choice,\n",
        "                messages=st.session_state.messages,\n",
        "                max_tokens=300,\n",
        "                temperature=0.5\n",
        "            )\n",
        "        bot_reply = response.choices[0].message.content.strip()\n",
        "        bot_reply = bot_reply.replace(\"\\n\\n\", \"\\n\")\n",
        "\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        st.markdown(f\"ü§ñ **Bot:**\\n\\n{bot_reply}\")\n",
        "\n",
        "        # ‚úÖ Cost calculation\n",
        "        usage = response.usage\n",
        "        cost = (\n",
        "            usage.prompt_tokens * TOKEN_PRICES[model_choice][\"input\"] +\n",
        "            usage.completion_tokens * TOKEN_PRICES[model_choice][\"output\"]\n",
        "        )\n",
        "        st.session_state.total_cost += cost\n",
        "\n",
        "# ‚úÖ Reset button\n",
        "if st.sidebar.button(\"üîÑ Reset Conversation\"):\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that ONLY answers questions about Supply Chain, Warehouse Automation, and AutoStore systems.\"}\n",
        "    ]\n",
        "    st.session_state.total_cost = 0.0\n",
        "    st.session_state.last_user_input = None\n",
        "    st.rerun()\n",
        "\n",
        "# ‚úÖ Sidebar cost\n",
        "st.sidebar.markdown(\"### üí∞ Session Cost\")\n",
        "st.sidebar.write(f\"Estimated Cost: **${st.session_state.total_cost:.4f}**\")\n",
        "\n",
        "# ‚úÖ Debug\n",
        "with st.sidebar.expander(\"üîç Debug - Conversation Log\"):\n",
        "    st.text_area(\"Model Input\", value=json.dumps(st.session_state.messages, indent=2), height=300)\n"
      ],
      "metadata": {
        "id": "Crv17IUfqqji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill $(ps aux | grep 'streamlit run' | awk '{print $2}') 2>/dev/null\n",
        "!kill $(ps aux | grep 'ngrok' | awk '{print $2}') 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rli1lh4tPXDx",
        "outputId": "77f02438-c3e7-48af-eea4-5050488aeed9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# üîë Paste your ngrok authtoken here:\n",
        "!ngrok config add-authtoken 30edlsk8qnaGeofWSstZV5QrFDL_4K5UUsUHTu11En6h4pKbJ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JItZfkKmFoJf",
        "outputId": "9b0facf1-50c3-4645-e0df-84d1923f8790"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(\"üîó Streamlit URL:\", public_url)\n",
        "\n",
        "!streamlit run app.py &>/dev/null&\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6FezMsXFzqf",
        "outputId": "b2e39aca-0b72-40de-c879-76b9adfc6c3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Streamlit URL: NgrokTunnel: \"https://7f639be4a515.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}